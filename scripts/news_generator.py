import os
import re
import json
import datetime
from google import genai

# ================= é…ç½®åŒº =================
API_KEY = os.environ.get("GEMINI_API_KEY")
HTML_FILE_PATH = "index.html"

def get_current_week_info():
    """è·å–å½“å‰çš„æ—¥æœŸã€å¹´ä»½å’Œå‘¨æ•°"""
    today = datetime.date.today()
    year, week_num, _ = today.isocalendar()
    return {
        "vol": f"VOL.{week_num:02d}",
        "week": f"Week {week_num:02d}",
        "date": today.strftime("%Y.%m.%d"),
        "year": str(year)
    }

def extract_json_from_text(text):
    """å°è¯•ä»æ··åˆæ–‡æœ¬ä¸­æå– JSON åˆ—è¡¨"""
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    try:
        # æå– ```json ... ```
        match = re.search(r'```json\s*(\[[\s\S]*?\])\s*```', text)
        if match:
            return json.loads(match.group(1))
        
        # æå– [ ... ]
        start = text.find('[')
        end = text.rfind(']')
        if start != -1 and end != -1:
            json_str = text[start:end+1]
            return json.loads(json_str)
            
    except Exception as e:
        print(f"JSON æå–å¤±è´¥: {e}")
    
    return None

def generate_news_content():
    """è°ƒç”¨ Gemini API ç”Ÿæˆæ–°é—»æ•°æ® (ä½¿ç”¨æ–°ç‰ˆ SDK)"""
    if not API_KEY:
        raise ValueError("âŒ é”™è¯¯: æœªæ‰¾åˆ° GEMINI_API_KEYã€‚è¯·åœ¨ GitHub Secrets ä¸­é…ç½®ã€‚")

    print(f"ğŸš€ æ­£åœ¨è¿æ¥ Gemini API (æ–°ç‰ˆ SDK)...")
    
    # å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨æ–°ç‰ˆ SDK å®¢æˆ·ç«¯
    client = genai.Client(api_key=API_KEY)

    prompt = f"""
    ä½ æ˜¯ä¸€åä¸“ä¸šã€çŠ€åˆ©ã€æœ‰æ·±åº¦çš„å›½é™…æ•™è‚²ä¸è®¾è®¡è‰ºæœ¯èµ„è®¯ä¸»ç¼–ã€‚
    ç°åœ¨æ˜¯ {datetime.date.today().strftime("%Yå¹´%mæœˆ%dæ—¥")}ã€‚

    è¯·æ£€ç´¢ã€æœ€è¿‘ 7 å¤©å†…é¦–æ¬¡å‘å¸ƒã€‘çš„ä¿¡æ¯ï¼Œå¹¶æŒ‰è¦æ±‚ç”Ÿæˆã€ŠRAC å‘¨æœ«é—ªè®¯ã€‹çš„å†…å®¹ã€‚

    ã€å†…å®¹ä¸»é¢˜èŒƒå›´ã€‘
    è¯·å›´ç»•ä»¥ä¸‹å…­ç±»èµ„è®¯è¿›è¡Œç­›é€‰ä¸æ•´ç†ï¼ˆ**æ¯ä¸ªæ¿å—å¿…é¡»åŒ…å« 5 æ¡èµ„è®¯ï¼Œæ€»å…± 30 æ¡**ï¼‰ï¼š
    1. global (ç¤¾ä¼šçƒ­ç‚¹ / å›½é™…æ–°é—»)
    2. education (æµ·å†…å¤–çƒ­ç‚¹æ•™è‚²ç±»æ–°é—»)
    3. university (ä¸–ç•Œé¡¶å°–é™¢æ ¡å®˜æ–¹åŠ¨æ€)
    4. design (æ•°å­—åª’ä½“ / æ¸¸æˆåŠ¨ç”» / äº¤äº’è®¾è®¡ / æ™ºèƒ½å·¥ç¨‹ / å»ºç­‘ / æ™¯è§‚ / åŸå¸‚ç›¸å…³ç±»/ å·¥ä¸šäº§å“ç±» / è§†è§‰ä¼ è¾¾/äº¤å‰å­¦ç§‘ç­‰ç›¸å…³ä¸“ä¸šçš„æœ¬ç§‘/ç¡•å£«ç•™å­¦ç”³è¯·è¶‹åŠ¿ã€å®˜æ–¹è¯¾ç¨‹ç»“æ„æˆ–åŸ¹å…»æ–¹å‘å˜åŒ–)
    5. summer (Summer School / æš‘æœŸç§‘ç ”é¡¹ç›®ä¿¡æ¯)
    6. competitions (æˆªæ­¢æ—¶é—´åœ¨æœªæ¥çš„å›½é™…æƒå¨ç«èµ›)

    ã€æ·±åº¦å†…å®¹ç”Ÿæˆè¦æ±‚ã€‘
    ä¸è¦åªå†™ç®€ä»‹ï¼**æ¯æ¡æ–°é—»å¿…é¡»æ˜¯ä¸€ç¯‡ 400-600 å­—çš„æ·±åº¦å¾®æŠ¥é“ã€‚**
    
    1.  **key_points**: æç‚¼ 3 ä¸ªæ ¸å¿ƒæƒ…æŠ¥ï¼ˆBullet pointsï¼‰ã€‚
    2.  **relevant_majors**: åˆ—å‡ºå—æ­¤æ–°é—»å½±å“çš„å…·ä½“è®¾è®¡/è‰ºæœ¯ä¸“ä¸šåç§°ï¼ˆè‹±æ–‡ï¼‰ã€‚
    3.  **fullContent**: 
        * å¿…é¡»åŒ…å« HTML æ ‡ç­¾ï¼ˆ`<h3>` å°æ ‡é¢˜, `<p>` æ®µè½, `<ul>` åˆ—è¡¨ï¼‰ã€‚
        * å†…å®¹å¿…é¡»è¯¦å®ï¼ŒåŒ…å«æ•°æ®æ”¯æŒã€èƒŒæ™¯åˆ†æå’Œæœªæ¥é¢„æµ‹ã€‚
    4.  **analysis**: é’ˆå¯¹å­¦ç”Ÿ/å®¶é•¿çš„çŠ€åˆ©ç‚¹è¯„ï¼ˆ2å¥è¯ï¼‰ï¼Œç›´å‡»ç—›ç‚¹ï¼Œç»™å‡ºè¡ŒåŠ¨å»ºè®®ã€‚
    5.  **url**: å¿…é¡»æ˜¯çœŸå®çš„åŸå§‹æ–°é—»é“¾æ¥ï¼Œä¸èƒ½ç•™ç©ºã€‚
    6.  **image**: å¿…é¡»æä¾›ä¸€å¼ ç›¸å…³å›¾ç‰‡çš„ URL (og:image)ã€‚

    ã€æ ¼å¼è¦æ±‚ã€‘
    è¯·ç›´æ¥è¾“å‡º JSON æ•°ç»„ï¼Œæ— éœ€ Markdown æ ‡è®°ã€‚
    """

    print("ğŸ” æ­£åœ¨è°ƒç”¨ Gemini API è¿›è¡Œæ·±åº¦å†…å®¹ç”Ÿæˆ... (Target: 30 items)")
    
    try:
        # å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨æ–°ç‰ˆ SDK çš„è°ƒç”¨æ–¹å¼
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt,
            config={
                'tools': [{'google_search': {}}], # æ–°ç‰ˆ SDK çš„æœç´¢å·¥å…·é…ç½®
                'response_mime_type': 'application/json' # å¼ºåˆ¶ JSON æ¨¡å¼
            }
        )
    except Exception as e:
        print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
        raise

    print("âœ… API å“åº”æˆåŠŸï¼Œæ­£åœ¨è§£æ JSON...")
    
    # æ–°ç‰ˆ SDK ç›´æ¥ä» response.text è·å–å†…å®¹
    news_data = extract_json_from_text(response.text)
    
    if not news_data:
        print("âŒ é”™è¯¯: æ— æ³•ä» AI å“åº”ä¸­æå–æœ‰æ•ˆçš„ JSON æ•°æ®ã€‚")
        print(f"åŸå§‹å“åº”ç‰‡æ®µ: {response.text[:500]}")
        raise ValueError("Invalid JSON response from AI")
        
    return news_data

def update_html_file(news_data, week_info):
    """è¯»å– index.html å¹¶æ›´æ–° JS æ•°æ®éƒ¨åˆ†"""
    if not os.path.exists(HTML_FILE_PATH):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° {HTML_FILE_PATH} æ–‡ä»¶")

    with open(HTML_FILE_PATH, 'r', encoding='utf-8') as f:
        content = f.read()

    # 1. æ›´æ–° ISSUE_CONFIG
    new_config_str = f"""const ISSUE_CONFIG = {{
            vol: "{week_info['vol']}",           
            week: "{week_info['week']}",         
            date: "{week_info['date']}",      
            year: "{week_info['year']}"
        }};"""
    
    content = re.sub(r'const\s+ISSUE_CONFIG\s*=\s*\{[\s\S]*?\};', new_config_str, content)

    # 2. æ›´æ–° SECTIONS
    static_props = {
        'global': {'subtitle': 'å…¨çƒè§†é‡', 'bgColor': 'bg-[#FF4D00]', 'textColor': 'text-white'},
        'education': {'subtitle': 'æ•™è‚²è§‚å¯Ÿ', 'bgColor': 'bg-[#CCFF00]', 'textColor': 'text-black'},
        'university': {'subtitle': 'é™¢æ ¡åŠ¨æ€', 'bgColor': 'bg-[#0047FF]', 'textColor': 'text-white'},
        'design': {'subtitle': 'å‰æ²¿è®¾è®¡', 'bgColor': 'bg-[#FF00FF]', 'textColor': 'text-white'},
        'summer': {'subtitle': 'å¤æ ¡ç§‘ç ”', 'bgColor': 'bg-[#00FF94]', 'textColor': 'text-black'},
        'competitions': {'subtitle': 'ç«èµ›ä¿¡æ¯', 'bgColor': 'bg-[#1A1A1A]', 'textColor': 'text-white'}
    }
    
    titles = {
        'global': 'GLOBAL NEWS', 'education': 'EDUCATION',
        'university': 'UNIVERSITY', 'design': 'TECH & DESIGN',
        'summer': 'LABS', 'competitions': 'COMPETITIONS'
    }

    js_sections_str = "const SECTIONS = [\n"
    global_id_counter = 1

    # å¤„ç† AI è¿”å›çš„æ•°æ®ï¼ˆå…¼å®¹åˆ—è¡¨æˆ–å­—å…¸ç»“æ„ï¼‰
    data_list = news_data if isinstance(news_data, list) else []
    
    # å»ºç«‹ ID åˆ°æ•°æ®çš„æ˜ å°„ï¼Œé˜²æ­¢ AI è¿”å›é¡ºåºé”™ä¹±
    data_map = {item['id']: item for item in data_list if 'id' in item}

    # æŒ‰ç…§æˆ‘ä»¬é¢„å®šä¹‰çš„é¡ºåºéå†æ¿å—
    for sec_key in ['global', 'education', 'university', 'design', 'summer', 'competitions']:
        section_data = data_map.get(sec_key, {'items': []})
        props = static_props.get(sec_key, {})
        display_title = titles.get(sec_key, sec_key.upper())
        
        js_sections_str += "            {\n"
        js_sections_str += f"                id: '{sec_key}',\n"
        js_sections_str += f"                title: '{display_title}',\n"
        js_sections_str += f"                subtitle: '{props.get('subtitle', '')}',\n"
        js_sections_str += f"                bgColor: '{props.get('bgColor', '')}',\n"
        js_sections_str += f"                textColor: '{props.get('textColor', '')}',\n"
        js_sections_str += "                items: [\n"
        
        items = section_data.get('items', [])
        for item in items:
            current_id = global_id_counter
            global_id_counter += 1

            clean_content = str(item.get('fullContent', '')).replace('\n', '').replace('"', '\\"').replace("'", "\\'")
            clean_summary = str(item.get('content', '')).replace('"', '\\"').replace("'", "\\'")
            clean_title = str(item.get('title', '')).replace('"', '\\"').replace("'", "\\'")
            clean_image = str(item.get('image', '')).replace('"', '\\"')
            clean_analysis = str(item.get('analysis', '')).replace('"', '\\"').replace("'", "\\'")
            clean_source = str(item.get('source', 'RAC News'))
            clean_date = str(item.get('date', ''))
            clean_url = str(item.get('url', '#'))
            
            tags = item.get('tags', [])
            tags_str = json.dumps(tags, ensure_ascii=False) if isinstance(tags, list) else "[]"
            
            majors = item.get('relevant_majors', [])
            majors_str = json.dumps(majors, ensure_ascii=False) if isinstance(majors, list) else "[]"

            kps = item.get('key_points', [])
            kps_str = json.dumps(kps, ensure_ascii=False) if isinstance(kps, list) else "[]"
            
            js_sections_str += "                    {\n"
            js_sections_str += f"                        id: {current_id},\n"
            js_sections_str += f"                        title: \"{clean_title}\",\n"
            js_sections_str += f"                        content: \"{clean_summary}\",\n"
            js_sections_str += f"                        source: \"{clean_source}\",\n"
            js_sections_str += f"                        date: \"{clean_date}\",\n"
            js_sections_str += f"                        image: \"{clean_image}\",\n"
            js_sections_str += f"                        tags: {tags_str},\n"
            js_sections_str += f"                        relevant_majors: {majors_str},\n"
            js_sections_str += f"                        key_points: {kps_str},\n"
            js_sections_str += f"                        url: \"{clean_url}\",\n"
            js_sections_str += f"                        fullContent: \"{clean_content}\",\n"
            js_sections_str += f"                        analysis: \"{clean_analysis}\"\n"
            js_sections_str += "                    },\n"
        
        js_sections_str += "                ]\n"
        js_sections_str += "            },\n"

    js_sections_str += "        ];"

    content = re.sub(r'const\s+SECTIONS\s*=\s*\[([\s\S]*?)\];', js_sections_str, content)

    with open(HTML_FILE_PATH, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… æˆåŠŸæ›´æ–° {HTML_FILE_PATH}ï¼ç‰ˆæœ¬: {week_info['vol']} ({week_info['date']})")

if __name__ == "__main__":
    try:
        print("ğŸ¬ å¼€å§‹æ‰§è¡Œå‘¨æ›´ä»»åŠ¡...")
        week_info = get_current_week_info()
        print(f"ğŸ“… ç›®æ ‡ç‰ˆæœ¬: {week_info['vol']} ({week_info['date']})")
        news_data = generate_news_content()
        update_html_file(news_data, week_info)
        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚")
    except Exception as e:
        print(f"âŒ ä»»åŠ¡å¤±è´¥: {e}")
        exit(1)
