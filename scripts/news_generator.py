import os
import json
import datetime
from google import genai

# ================= é…ç½®åŒº =================
API_KEY = os.environ.get("GEMINI_API_KEY")
HTML_FILE_PATH = "index.html"

def get_current_week_info():
    """è·å–å½“å‰çš„æ—¥æœŸã€å¹´ä»½å’Œå‘¨æ•°"""
    today = datetime.date.today()
    year, week_num, _ = today.isocalendar()
    return {
        "vol": f"VOL.{week_num:02d}",
        "week": f"Week {week_num:02d}",
        "date": today.strftime("%Y.%m.%d"),
        "year": str(year)
    }

def generate_news_content():
    """è°ƒç”¨ Gemini API ç”Ÿæˆæ–°é—»æ•°æ®"""
    if not API_KEY:
        raise ValueError("âŒ é”™è¯¯: æœªæ‰¾åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚")

    print(f"ğŸš€ æ­£åœ¨è¿æ¥ Gemini API (key length: {len(API_KEY)})...")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = genai.Client(api_key=API_KEY)

    # æ ¸å¿ƒ Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€åä¸¥æ ¼éµå®ˆäº‹å®æ ¸æŸ¥ä¸ä¿¡æ¯æº¯æºè§„èŒƒçš„å›½é™…æ•™è‚²ä¸å…¨çƒèµ„è®¯ç¼–è¾‘ã€‚
    ç°åœ¨æ˜¯ {datetime.date.today().strftime("%Yå¹´%mæœˆ%dæ—¥")}ã€‚

    è¯·æ£€ç´¢ã€æœ€è¿‘ 7 å¤©å†…é¦–æ¬¡å‘å¸ƒã€‘çš„ä¿¡æ¯ï¼Œå¹¶æŒ‰è¦æ±‚ç”Ÿæˆã€ŠRAC å‘¨æœ«é—ªè®¯ã€‹çš„å†…å®¹ã€‚

    ã€ä¿¡æ¯æ¥æºè¦æ±‚ã€‘
    ä»…é™ï¼šå¾®åš/å…¬ä¼—å·ï¼ˆé«˜æ ¡/æƒå¨åª’ä½“ï¼‰ã€æƒå¨æ–°é—»åª’ä½“ï¼ˆBBC/Reuters/FT/NYTimesç­‰ï¼‰ã€æµ·å¤–å¤§å­¦å®˜æ–¹ç¤¾åª’ã€‚
    ã€æ˜ç¡®æ’é™¤ã€‘
    ä»»ä½•æ•™åŸ¹ä¸­ä»‹å•†ä¸šæ¨å¹¿ï¼ˆæ–°ä¸œæ–¹/å¯å¾·ç­‰ï¼‰ã€è§‚ç‚¹è¯„è®ºã€æœªç»è¯å®ä¿¡æ¯ã€‚

    ã€å†…å®¹ä¸»é¢˜èŒƒå›´ã€‘
    è¯·å›´ç»•ä»¥ä¸‹å…­ç±»èµ„è®¯è¿›è¡Œç­›é€‰ä¸æ•´ç†ï¼ˆ**æ¯ä¸ªæ¿å—å¿…é¡»åŒ…å« 5 æ¡èµ„è®¯ï¼Œæ€»å…± 30 æ¡**ï¼‰ï¼š
    1. global (ç¤¾ä¼šçƒ­ç‚¹ / å›½é™…æ–°é—»)
    2. education (æµ·å†…å¤–çƒ­ç‚¹æ•™è‚²ç±»æ–°é—»)
    3. university (ä¸–ç•Œé¡¶å°–é™¢æ ¡å®˜æ–¹åŠ¨æ€)
    4. design (æ•°å­—åª’ä½“ / æ¸¸æˆåŠ¨ç”» / äº¤äº’è®¾è®¡ / æ™ºèƒ½å·¥ç¨‹ / å»ºç­‘ / æ™¯è§‚ / åŸå¸‚ç›¸å…³ç±»/ å·¥ä¸šäº§å“ç±» / è§†è§‰ä¼ è¾¾/äº¤å‰å­¦ç§‘ç­‰ç›¸å…³ä¸“ä¸šçš„æœ¬ç§‘/ç¡•å£«ç•™å­¦ç”³è¯·è¶‹åŠ¿ã€å®˜æ–¹è¯¾ç¨‹ç»“æ„æˆ–åŸ¹å…»æ–¹å‘å˜åŒ–)
    5. summer (Summer School / æš‘æœŸç§‘ç ”é¡¹ç›®ä¿¡æ¯)
    6. competitions (æˆªæ­¢æ—¶é—´åœ¨æœªæ¥çš„å›½é™…æƒå¨ç«èµ›)

    ã€JSON è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
    è¯·ç›´æ¥è¾“å‡ºä»¥ä¸‹ JSON ç»“æ„ï¼š
    [
        {{
            "id": "global",
            "items": [
                {{
                    "title": "æ ‡é¢˜ (Emoji + ä¸­æ–‡)", 
                    "content": "**å…³é”®è¯**ï¼šä¸¤è¡Œæ‘˜è¦...", 
                    "source": "å‘å¸ƒæ–¹", 
                    "date": "MM.DD", 
                    "image": "https://...",
                    "tags": ["Tag1", "Tag2"],
                    "relevant_majors": ["Interaction Design", "HCI"],
                    "key_points": ["æ ¸å¿ƒç‚¹1", "æ ¸å¿ƒç‚¹2", "æ ¸å¿ƒç‚¹3"],
                    "url": "https://... (å¿…é¡»æ˜¯çœŸå®é“¾æ¥)",
                    "fullContent": "<h3>å°æ ‡é¢˜</h3><p>è¯¦ç»†å†…å®¹(400-600å­—)...</p>",
                    "analysis": "ä¸“å®¶ç‚¹è¯„(2å¥è¯)..."
                }}
            ]
        }}
    ]
    """

    print("ğŸ” æ­£åœ¨è°ƒç”¨ Gemini API (Model: gemini-2.0-flash-exp)...")
    
    try:
        # ä½¿ç”¨çº¯å­—å…¸é…ç½®ï¼Œè¿™æ˜¯æœ€å…¼å®¹çš„æ–¹å¼
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt,
            config={
                'tools': [{'google_search': {}}], # å¯ç”¨æœç´¢
                'response_mime_type': 'application/json' # å¼ºåˆ¶ JSON æ¨¡å¼
            }
        )
    except Exception as e:
        print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
        raise

    print("âœ… API å“åº”æˆåŠŸï¼Œæ­£åœ¨è§£æ JSON...")
    
    try:
        # JSON Mode ä¸‹ï¼Œresponse.text åº”è¯¥ç›´æ¥æ˜¯åˆæ³•çš„ JSON å­—ç¬¦ä¸²
        news_data = json.loads(response.text)
        return news_data
    except json.JSONDecodeError:
        print("âŒ é”™è¯¯: æ— æ³•è§£æ AI è¿”å›çš„ JSONã€‚")
        print(f"åŸå§‹å“åº”: {response.text[:500]}...")
        raise

def update_html_file(news_data, week_info):
    """è¯»å– index.html å¹¶æ›´æ–° JS æ•°æ®éƒ¨åˆ†"""
    if not os.path.exists(HTML_FILE_PATH):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° {HTML_FILE_PATH} æ–‡ä»¶")

    with open(HTML_FILE_PATH, 'r', encoding='utf-8') as f:
        content = f.read()

    # 1. æ›´æ–° ISSUE_CONFIG
    new_config_str = f"""const ISSUE_CONFIG = {{
            vol: "{week_info['vol']}",           
            week: "{week_info['week']}",         
            date: "{week_info['date']}",      
            year: "{week_info['year']}"
        }};"""
    
    content = re.sub(
        r'const\s+ISSUE_CONFIG\s*=\s*\{[\s\S]*?\};', 
        new_config_str, 
        content
    )

    # 2. æ›´æ–° SECTIONS
    static_props = {
        'global': {'subtitle': 'å…¨çƒè§†é‡', 'bgColor': 'bg-[#FF4D00]', 'textColor': 'text-white'},
        'education': {'subtitle': 'æ•™è‚²è§‚å¯Ÿ', 'bgColor': 'bg-[#CCFF00]', 'textColor': 'text-black'},
        'university': {'subtitle': 'é™¢æ ¡åŠ¨æ€', 'bgColor': 'bg-[#0047FF]', 'textColor': 'text-white'},
        'design': {'subtitle': 'å‰æ²¿è®¾è®¡', 'bgColor': 'bg-[#FF00FF]', 'textColor': 'text-white'},
        'summer': {'subtitle': 'å¤æ ¡ç§‘ç ”', 'bgColor': 'bg-[#00FF94]', 'textColor': 'text-black'},
        'competitions': {'subtitle': 'ç«èµ›ä¿¡æ¯', 'bgColor': 'bg-[#1A1A1A]', 'textColor': 'text-white'}
    }
    
    titles = {
        'global': 'GLOBAL NEWS', 'education': 'EDUCATION',
        'university': 'UNIVERSITY', 'design': 'TECH & DESIGN',
        'summer': 'LABS', 'competitions': 'COMPETITIONS'
    }

    js_sections_str = "const SECTIONS = [\n"
    
    global_id_counter = 1

    for section_data in news_data:
        sec_id = section_data['id']
        props = static_props.get(sec_id, {})
        display_title = titles.get(sec_id, sec_id.upper())
        
        js_sections_str += "            {\n"
        js_sections_str += f"                id: '{sec_id}',\n"
        js_sections_str += f"                title: '{display_title}',\n"
        js_sections_str += f"                subtitle: '{props.get('subtitle', '')}',\n"
        js_sections_str += f"                bgColor: '{props.get('bgColor', '')}',\n"
        js_sections_str += f"                textColor: '{props.get('textColor', '')}',\n"
        js_sections_str += "                items: [\n"
        
        items = section_data.get('items', [])
        for item in items:
            current_id = global_id_counter
            global_id_counter += 1

            clean_content = str(item.get('fullContent', '')).replace('\n', '').replace('"', '\\"').replace("'", "\\'")
            clean_summary = str(item.get('content', '')).replace('"', '\\"').replace("'", "\\'")
            clean_title = str(item.get('title', '')).replace('"', '\\"').replace("'", "\\'")
            clean_image = str(item.get('image', '')).replace('"', '\\"')
            clean_analysis = str(item.get('analysis', '')).replace('"', '\\"').replace("'", "\\'")
            clean_source = str(item.get('source', 'RAC News'))
            clean_date = str(item.get('date', ''))
            clean_url = str(item.get('url', '#'))
            
            tags = item.get('tags', [])
            tags_str = json.dumps(tags, ensure_ascii=False) if isinstance(tags, list) else "[]"
            
            majors = item.get('relevant_majors', [])
            majors_str = json.dumps(majors, ensure_ascii=False) if isinstance(majors, list) else "[]"

            kps = item.get('key_points', [])
            kps_str = json.dumps(kps, ensure_ascii=False) if isinstance(kps, list) else "[]"
            
            js_sections_str += "                    {\n"
            js_sections_str += f"                        id: {current_id},\n"
            js_sections_str += f"                        title: \"{clean_title}\",\n"
            js_sections_str += f"                        content: \"{clean_summary}\",\n"
            js_sections_str += f"                        source: \"{clean_source}\",\n"
            js_sections_str += f"                        date: \"{clean_date}\",\n"
            js_sections_str += f"                        image: \"{clean_image}\",\n"
            js_sections_str += f"                        tags: {tags_str},\n"
            js_sections_str += f"                        relevant_majors: {majors_str},\n"
            js_sections_str += f"                        key_points: {kps_str},\n"
            js_sections_str += f"                        url: \"{clean_url}\",\n"
            js_sections_str += f"                        fullContent: \"{clean_content}\",\n"
            js_sections_str += f"                        analysis: \"{clean_analysis}\"\n"
            js_sections_str += "                    },\n"
        
        js_sections_str += "                ]\n"
        js_sections_str += "            },\n"

    js_sections_str += "        ];"

    content = re.sub(
        r'const\s+SECTIONS\s*=\s*\[([\s\S]*?)\];', 
        js_sections_str, 
        content
    )

    with open(HTML_FILE_PATH, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… æˆåŠŸæ›´æ–° {HTML_FILE_PATH}ï¼ç‰ˆæœ¬: {week_info['vol']} ({week_info['date']})")

if __name__ == "__main__":
    try:
        print("ğŸ¬ å¼€å§‹æ‰§è¡Œå‘¨æ›´ä»»åŠ¡...")
        week_info = get_current_week_info()
        print(f"ğŸ“… ç›®æ ‡ç‰ˆæœ¬: {week_info['vol']} ({week_info['date']})")
        
        news_data = generate_news_content()
        update_html_file(news_data, week_info)
        
        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚")
    except Exception as e:
        print(f"âŒ ä»»åŠ¡å¤±è´¥: {e}")
        exit(1)
